paper_name, href, publish, comment, year
Fast bayesian optimization of machine learning hyperparameters on large datasets,-,-,-,2016
Learning transferable architectures for scalable image recognition,-,-,-,2017
Regularized evolution for image classiﬁer architecture search,-,-,-,2018
Towards automated deep learning: Efﬁcient joint neural architecture and hyperparameter search,-,-,-,2018
Multi-Fidelity Automatic Hyper-Parameter Tuning via Transfer Series Expansion,-,-,multi fidelity,2019
Transfer learning with neural automl,-,-,transfer learning,2018
Network morphism,-,-,transfer learning,2016
Net2net: Accelerating learning via knowledge transfer,-,-,transfer learning,2015
Surrogate benchmarks for hyperparameter optimization,-,ECAI,surrogate,2014
An evaluation of adaptive surrogate modeling based optimization with two benchmark problems,-,-,surrogate,2014
Efﬁcient benchmarking of hyperparameter optimizers via surrogates,-,-,surrogate,2015
Surrogate-based methods for black-box optimization,-,-,surrogate,2017
Progressive neural architecture search,-,-,surrogate,2017
Learning curve prediction with bayesian neural networks,-,-,early stopping,2016
Peephole: Predicting network performance before training,-,-,surrogate,2017
Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves,-,-,early stopping,2015
Early stopping without a validation set,-,-,early stopping,2017
Performance Prediction Based on Neural Architecture Features,https://ieeexplore.ieee.org/abstract/document/8901943,CCHI,surrogate,2019
Ranking architectures using meta-learning,https://arxiv.org/abs/1911.11481,-,surrogate,2019
Meta-Learning of Neural Architectures for Few-Shot Learning,https://arxiv.org/abs/1911.11090,-,few-shot,2019
Exploiting Operation Importance for Differentiable Neural Architecture Search,https://arxiv.org/abs/1911.10511,-,-,2019
Multi-Objective Neural Architecture Search via Predictive Network Performance Optimization,https://arxiv.org/abs/1911.09336,-,surrogate,2019
Periodic Spectral Ergodicity: A Complexity Measure for Deep Neural Networks and Neural Architecture Search,https://arxiv.org/abs/1911.07831,-,-,2019